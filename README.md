# LLM-Text-detection
The emergence of Large Language Models (LLMs) has instilled apprehensions, particularly in the education sector, where concerns revolve around the potential impact of LLM-generated content on student writing skills and assessments. A critical challenge lies in effectively distinguishing between text authored by LLMs and that crafted by human writers.
The methodology employed in our approach is characterized by its comprehensive and sophisticated nature. A diverse array of machine learning models is incorporated, encompassing linear regression, stochastic gradient descent (SGD), LightGBM Classifier, CatBoost, decision tree, random forest, and a voting classifier utilized as an ensemble method. This strategic amalgamation aims to leverage the distinctive strengths of each model, fostering a synergistic effect that enhances the overall predictive capability of the system.
To further refine and optimize the model's performance, advanced techniques such as Byte Pair Encoding and TFIdfVectorizer are seamlessly integrated. These techniques play a pivotal role in capturing nuanced patterns and features within the data, contributing to the model's ability to make precise distinctions between content generated by LLMs and that produced by human authors.
The noteworthy outcomes achieved by our model underscore its efficacy in navigating the complexities of authorship identification. This provides educators and evaluators with a robust tool to discern between LLM-generated text and genuine human-written content. The heightened accuracy achieved by our models addresses concerns within the educational landscape, offering a dependable means to ensure the integrity of student assessments and preserve the value of human writing skills, even in an era increasingly influenced by language technologies.
